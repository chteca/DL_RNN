{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from random import shuffle\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "STRING_SIZE = 60\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 0.05\n",
    "SHIFT = 15\n",
    "CHARS = set('abcdefghijklmnopqrstuvwxyz')\n",
    "INDEX_TO_CHAR = [' '] + [w for w in CHARS]\n",
    "CHAR_TO_INDEX = {w: i for i, w in enumerate(INDEX_TO_CHAR)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, file_name, step):\n",
    "        self.file_name = file_name\n",
    "        self.step = step\n",
    "        self.text_array, self.X, self.Y = [], [], []\n",
    "        self.X_tensor, self.Y_tensor = torch.empty(1, 1), torch.empty(1, 1)\n",
    "        self.data = []\n",
    "\n",
    "    def get_text_array(self):\n",
    "        with open(self.file_name, encoding='utf-8') as file:\n",
    "            while True:\n",
    "                text = file.read(self.step).lower()\n",
    "                if not text:\n",
    "                    break\n",
    "                self.text_array.append(text)\n",
    "        del self.text_array[-1]\n",
    "        file.close()\n",
    "        return self.text_array\n",
    "\n",
    "    def shuffle_data(self):\n",
    "        shuffle(self.text_array)\n",
    "        return self.text_array\n",
    "\n",
    "    def create_data_tensors(self):\n",
    "        for sen in self.text_array:\n",
    "            y = [CHAR_TO_INDEX.get(char, CHAR_TO_INDEX[' ']) for char in sen]\n",
    "            x = [CHAR_TO_INDEX.get((chr((ord(char) - 97 + SHIFT) % 26 + 97) if char.isalpha() else char), CHAR_TO_INDEX[' ']) for char in sen]\n",
    "            self.Y.append(y)\n",
    "            self.X.append(x)\n",
    "            self.X_tensor = torch.tensor(self.X)\n",
    "            self.Y_tensor = torch.tensor(self.Y)\n",
    "        return self.X_tensor, self.Y_tensor\n",
    "\n",
    "    def use_dataloader(self):\n",
    "        dataset = torch.utils.data.TensorDataset(self.X_tensor, self.Y_tensor)\n",
    "        self.data = torch.utils.data.DataLoader(dataset, BATCH_SIZE, shuffle=True)\n",
    "        return self.data\n",
    "\n",
    "    def preprocess_data_val(self):\n",
    "        self.get_text_array()\n",
    "        self.shuffle_data()\n",
    "        self.create_data_tensors()\n",
    "        return self.X_tensor, self.Y_tensor\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        self.preprocess_data_val()\n",
    "        self.use_dataloader()\n",
    "        return self.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = Data(file_name = 'text.txt', step = STRING_SIZE).preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = Data(file_name = 'test.txt', step = STRING_SIZE).preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = torch.nn.Embedding(len(CHAR_TO_INDEX), 32)\n",
    "        self.rnn = torch.nn.RNN(32, 128, batch_first=True)\n",
    "        self.linear = torch.nn.Linear(128, len(CHAR_TO_INDEX))\n",
    "\n",
    "    def forward(self, sentence, state=None):\n",
    "        embed = self.embed(sentence)\n",
    "        o, h = self.rnn(embed)\n",
    "        return self.linear(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel()\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 72.1655, acc: 0.6383 | test loss: 14.9163, test acc: 0.8328 | 1.94 sec.\n",
      "Epoch: 1, loss: 36.7910, acc: 0.8777 | test loss: 8.5558, test acc: 0.9039 | 1.76 sec.\n",
      "Epoch: 2, loss: 22.6537, acc: 0.9230 | test loss: 5.5947, test acc: 0.9480 | 1.65 sec.\n",
      "Epoch: 3, loss: 15.4741, acc: 0.9572 | test loss: 3.9234, test acc: 0.9693 | 1.59 sec.\n",
      "Epoch: 4, loss: 11.1936, acc: 0.9711 | test loss: 2.8760, test acc: 0.9838 | 1.69 sec.\n",
      "Epoch: 5, loss: 8.4749, acc: 0.9823 | test loss: 2.2320, test acc: 0.9862 | 1.51 sec.\n",
      "Epoch: 6, loss: 6.6604, acc: 0.9858 | test loss: 1.7641, test acc: 0.9884 | 1.43 sec.\n",
      "Epoch: 7, loss: 5.3881, acc: 0.9884 | test loss: 1.4455, test acc: 0.9898 | 1.70 sec.\n",
      "Epoch: 8, loss: 4.4777, acc: 0.9905 | test loss: 1.2061, test acc: 0.9917 | 1.44 sec.\n",
      "Epoch: 9, loss: 3.7952, acc: 0.9917 | test loss: 1.0365, test acc: 0.9951 | 1.50 sec.\n",
      "Epoch: 10, loss: 3.2793, acc: 0.9949 | test loss: 0.8925, test acc: 0.9970 | 1.48 sec.\n",
      "Epoch: 11, loss: 2.8677, acc: 0.9961 | test loss: 0.7893, test acc: 0.9975 | 1.17 sec.\n",
      "Epoch: 12, loss: 2.5413, acc: 0.9966 | test loss: 0.6950, test acc: 0.9977 | 1.68 sec.\n",
      "Epoch: 13, loss: 2.2750, acc: 0.9967 | test loss: 0.6288, test acc: 0.9977 | 1.46 sec.\n",
      "Epoch: 14, loss: 2.0574, acc: 0.9967 | test loss: 0.5668, test acc: 0.9977 | 1.54 sec.\n",
      "Epoch: 15, loss: 1.8680, acc: 0.9968 | test loss: 0.5251, test acc: 0.9974 | 1.35 sec.\n",
      "Epoch: 16, loss: 1.7161, acc: 0.9967 | test loss: 0.4741, test acc: 0.9977 | 1.41 sec.\n",
      "Epoch: 17, loss: 1.5809, acc: 0.9968 | test loss: 0.4366, test acc: 0.9977 | 1.07 sec.\n",
      "Epoch: 18, loss: 1.4686, acc: 0.9967 | test loss: 0.4170, test acc: 0.9974 | 0.97 sec.\n",
      "Epoch: 19, loss: 1.3684, acc: 0.9968 | test loss: 0.3875, test acc: 0.9974 | 0.98 sec.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss, train_acc, iter_num = .0, .0, .0\n",
    "    start_epoch_time = time.time()\n",
    "    model.train()\n",
    "    for x_in, y_in in data_train:\n",
    "        x_in = x_in\n",
    "        y_in = y_in.view(1, -1).squeeze()\n",
    "        optimizer.zero_grad()\n",
    "        out = model.forward(x_in).view(-1, len(CHAR_TO_INDEX))\n",
    "        l = loss(out, y_in)\n",
    "        train_loss += l.item()\n",
    "        batch_acc = (out.argmax(dim=1) == y_in)\n",
    "        train_acc += batch_acc.sum().item() / batch_acc.shape[0]\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        iter_num += 1\n",
    "    print(\n",
    "        f\"Epoch: {epoch}, loss: {train_loss:.4f}, acc: \"\n",
    "        f\"{train_acc / iter_num:.4f}\",\n",
    "        end=\" | \"\n",
    "    )\n",
    "    test_loss, test_acc, iter_num = .0, .0, .0\n",
    "    model.eval()\n",
    "    for x_in, y_in in data_test:\n",
    "        x_in = x_in\n",
    "        y_in = y_in.view(1, -1).squeeze()\n",
    "        out = model.forward(x_in).view(-1, len(CHAR_TO_INDEX))\n",
    "        l = loss(out, y_in)\n",
    "        test_loss += l.item()\n",
    "        batch_acc = (out.argmax(dim=1) == y_in)\n",
    "        test_acc += batch_acc.sum().item() / batch_acc.shape[0]\n",
    "        iter_num += 1\n",
    "    print(\n",
    "        f\"test loss: {test_loss:.4f}, test acc: {test_acc / iter_num:.4f} | \"\n",
    "        f\"{time.time() - start_epoch_time:.2f} sec.\"\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, Y_val = Data(file_name = 'val.txt', step = STRING_SIZE).preprocess_data_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy is : 0.9967\n",
      "--------------------\n",
      "Validation sentence is: \"to an english lawyer named norton     but she could not love\"\n",
      "--------------------\n",
      "True sentence is:       \"to an english lawyer named norton     but she could not love\"\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "val_results = model(X_val).argmax(dim=2)\n",
    "val_acc = (val_results == Y_val).flatten()\n",
    "val_acc = (val_acc.sum() / val_acc.shape[0]).item()\n",
    "out_sentence = \"\".join([INDEX_TO_CHAR[i] for i in val_results[idx]])\n",
    "true_sentence = \"\".join([INDEX_TO_CHAR[i] for i in Y_val[idx]])\n",
    "print(f\"Validation accuracy is : {val_acc:.4f}\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"Validation sentence is: \\\"{out_sentence}\\\"\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"True sentence is:       \\\"{true_sentence}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: перед нами стояла задача дешифровки шифра Цезаря. Для ее решения была использована простая модель рекуррентной нейронной сети. Точность дешифровки на валидационной выборке составила 0,9967."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
